{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9224148",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python ver. 확인 - 3.7 이상 or 이하 코드 다름\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89c5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#설치 코드\n",
    "!pip install bs4\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0507a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import csv \n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.common.exceptions import UnexpectedAlertPresentException\n",
    "import urllib.request\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "from selenium.webdriver.common.by import By #python ver.3.7 이상일 경우 추가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe68bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#기간 설정\n",
    "first_days = pd.date_range('2021/11/01', '2022/10/31', freq='MS')\n",
    "last_days = pd.date_range('2021/11/01', '2022/10/31', freq='M')\n",
    "\n",
    "#키워드 설정 - 단독 키워드 or 네이버 검색 연산자 사용 결합 키워드 입력\n",
    "self_keyword = [\"(대학생 | 과제 | 시험 | 팀플 | 종강 | 개강 | 밤샘 | 공강 | 과방 | 동방 | 랩실 | 중도 | 학식) +점메추\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef1a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#크롤링 범위\n",
    "#블로그 (카페제외)\n",
    "#본문 (제목 & 댓글 제외)\n",
    "#기간: 포스트 코로나 - 최근 1년 (2021. 11. 01 ~ 2022. 10. 31)\n",
    "#네이버 View가 한 번에 1000개까지 검색되는 점을 고려하여, 날짜를 월 단위로 쪼개어 매월 당 최대 1000개씩을 크롤링함\n",
    "\n",
    "#은지 할당 키워드 - \"쇼핑\"\n",
    "#쇼핑 + (대학생 | 용돈 | 알바 | 장학금 | 새내기 | 복학생 | 자취생 | 수업 끝 | 오티 | 엠티)\n",
    "#Self keyword = 지그재그, 무신사, 에이블리, 브랜디, 개강룩, 새내기룩, OOTD\n",
    "#Sub keyword = 언박싱, 친환경, -로그, 손민수, 왓츠인마이백, 랜선집들이, 불매, 장비빨, 앱등이/삼엽충, 당근/쿨거래/네고/매너온도, 봄웜/여쿨/갈웜/겨쿨, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83137301",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d49b802",
   "metadata": {
    "id": "FBbQm7ncGCDR"
   },
   "source": [
    "### 요청한 만큼 스크롤이 내려간 VIEW 페이지에서 url을 긁어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f4367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_url_list=[]\n",
    "\n",
    "for keyword in self_keyword:\n",
    "    url = 'https://search.naver.com/search.naver?sm=tab_hty.top&where=blog&query={}&oquery={}'.format(keyword, keyword)\n",
    "    \n",
    "    driver = webdriver.Chrome('./chromedriver.exe') #크롬 드라이버 위치 변경 필요\n",
    "    driver.implicitly_wait(3)\n",
    "    \n",
    "    driver.get(url)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    url_want = 1020  #default:1020\n",
    "    \n",
    "    driver.find_element(By.XPATH,r'//*[@id=\"snb\"]/div[1]/div/div[2]/a').click() #python ver.3.7 이상: driver.find_element(By.XPATH,\n",
    "    \n",
    "    for k in range(len(first_days)):\n",
    "        try:\n",
    "            driver.find_element(By.XPATH,'//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[1]/a[9]/i').click()\n",
    "            driver.find_element(By.XPATH,'//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[1]/div/div/div/ul/li[{0}]'.format(first_days.year[k]-2002)).click()\n",
    "            driver.find_element(By.XPATH,'//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[2]/div/div/div/ul/li[{0}]/a'.format(first_days.month[k])).click()\n",
    "            driver.find_element(By.XPATH,'//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[3]/div/div/div/ul/li[{0}]/a'.format(first_days.day[k])).click()\n",
    "            driver.find_element(By.XPATH,'//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[1]/span[3]/a').click()\n",
    "            driver.find_element(By.XPATH,'//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[1]/div/div/div/ul/li[{0}]'.format(last_days.year[k]-2002)).click()\n",
    "            driver.find_element(By.XPATH,'//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[2]/div/div/div/ul/li[{0}]/a'.format(last_days.month[k])).click()\n",
    "            driver.find_element(By.XPATH,'//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[2]/div[3]/div/div/div/ul/li[{0}]/a'.format(last_days.day[k])).click()\n",
    "            driver.find_element(By.XPATH,'//*[@id=\"snb\"]/div[2]/ul/li[3]/div/div[2]/div[3]/button').click()\n",
    "        \n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\") \n",
    "\n",
    "            scroll = (url_want/30)-1 \n",
    "        \n",
    "            for i in range(int(scroll)):\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(random.uniform(1,1.7))\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:   \n",
    "                    break\n",
    "                                                                             \n",
    "                last_height = new_height\n",
    "                                    \n",
    "            soup = bs(driver.page_source, 'lxml') \n",
    "            blog_url = soup.find_all('a',class_='api_txt_lines total_tit')\n",
    "\n",
    "            for i in blog_url:\n",
    "                blog_url_list.append(i['href'])\n",
    "            \n",
    "            print('{0} 키워드 {1}년{2}월'.format(keyword, first_days.year[k], first_days.month[k]), len(blog_url),' 개 블로그 url주소 수집')\n",
    "\n",
    "        \n",
    "            driver.execute_script(\"window.scrollTo(0, 0)\")\n",
    "        \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bae8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a63bef0c",
   "metadata": {
    "id": "FBbQm7ncGCDR"
   },
   "source": [
    "### 수집 후 blog_url_list를 set type으로 전환해 혹시 중복된 url이 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ed1cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_list = set(blog_url_list)\n",
    "blog_url_list = list(real_list)\n",
    "len(blog_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945d5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7839f2d",
   "metadata": {},
   "source": [
    "### #본문 & url 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e23d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_naver_blog1=[]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#본문 & url 수집\n",
    "time_list = []\n",
    "review_list = []\n",
    "url_list = []\n",
    "count = 0\n",
    "\n",
    "driver = webdriver.Chrome('./chromedriver.exe')  #크롬 드라이버 위치 변경 필요\n",
    "for url in tqdm(blog_url_list): #기본적으로 고치지 않지만, n번째 크롤링에서 멈췄다면, blog_url_list를 blog_url_list[n:]으로 고침\n",
    "    if 'naver' in url:\n",
    "    \n",
    "        count += 1\n",
    "        driver.get(url)\n",
    "        time.sleep(1.1)\n",
    "\n",
    "        try:\n",
    "            \n",
    "            driver.switch_to.frame('mainFrame') \n",
    "            time.sleep(1)\n",
    "        \n",
    "            soup = bs(driver.page_source, 'lxml') \n",
    "            postview = soup.find('div', attrs={'id': re.compile('post-view.+')}).get_text()\n",
    "\n",
    "            reg = re.compile(r'[\\s+]')\n",
    "            postview_reg = reg.sub(' ',postview)\n",
    "\n",
    "            try:\n",
    "                timeline = driver.find_element(By.XPATH,\"//span[@class='se_publishDate pcol2']\")\n",
    "        \n",
    "            except:\n",
    "                timeline = driver.find_element(By.XPATH,\"//p[@class='date fil5 pcol2 _postAddDate']\")\n",
    "            timeline = timeline.text\n",
    "\n",
    "    \n",
    "             \n",
    "            time_list.append(timeline)\n",
    "            review_list.append(postview_reg)\n",
    "            url_list.append(url)\n",
    "            time.sleep(random.uniform(1,1.7))\n",
    "        except UnexpectedAlertPresentException:\n",
    "            pass\n",
    "    else:\n",
    "        no_naver_blog1.append(url)\n",
    "        print('네이버 블로그 아닌 url: ',url)\n",
    "        \n",
    "    if count%10 ==0:\n",
    "        print('{}개 블로그 크롤링 완료'.format(count))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a1e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'time' : time_list,\n",
    "        'review' : review_list,\n",
    "        'url': url_list}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print('걸린 시간: ', time.time()-start)\n",
    "print('최종 {}개 블로그 크롤링 완료'.format(count))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c27fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv 파일로 저장\n",
    "df.to_csv(\"점메추_성률1.csv\", encoding = \"utf-8-sig\") #파일 이름 변경 필요 \"title_keyword\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
