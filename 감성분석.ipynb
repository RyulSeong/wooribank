{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36062b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/park1200656/KnuSentiLex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2345816",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff47c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e374b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import ast\n",
    "\n",
    "!pip3 install pyldavis\n",
    "import pyLDAvis.sklearn\n",
    "from tqdm import tqdm\n",
    "from konlpy.tag import Okt\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "#import MeCab\n",
    "import os\n",
    "import jpype\n",
    "from matplotlib import rc\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bad757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 감성 사전으로 단어를 평가하는 함수\n",
    "# token = 문자열 단어\n",
    "def score_word(token):\n",
    "    with open('KnuSentiLex/data/SentiWord_info.json', encoding='utf-8-sig', mode='r') as f:\n",
    "        data = json.load(f)\n",
    "    result = ['None','None']\n",
    "    for i in range(0, len(data)):\n",
    "        if data[i]['word'] == token:\n",
    "            result.pop()\n",
    "            result.pop()\n",
    "            result.append(data[i]['word_root'])\n",
    "            result.append(data[i]['polarity'])\n",
    "    return result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbd397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장을 평가하는 함수\n",
    "# sentence = 문자열 문장\n",
    "def score_sentence(sentence):\n",
    "    tokens = okt.pos(sentence, stem = True)\n",
    "    \n",
    "    token = []\n",
    "    test = []\n",
    "    for i in tokens:\n",
    "        token.append(i[0])\n",
    "        test.append(score_word(i[0]))\n",
    "    \n",
    "    prenegative = [\"안\", \"못\"]\n",
    "    sunegative = [\"않다\", \"모르다\"]\n",
    "    adjust = []\n",
    "    \n",
    "    for a, i in enumerate(test):\n",
    "\n",
    "        try:\n",
    "            if token[a - 1] in prenegative:\n",
    "                adjust.append(int(i) * -1)\n",
    "            else:\n",
    "                adjust.append(i)\n",
    "        except:\n",
    "            adjust.append(i)\n",
    "            \n",
    "    adjust2 = []\n",
    "    for a, i in enumerate(adjust):        \n",
    "        try:\n",
    "            if token[a + 1] in sunegative:\n",
    "                adjust2.append(int(i) * -1)\n",
    "            else:\n",
    "                adjust2.append(i)\n",
    "        except:\n",
    "            adjust2.append(i)\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            adjust2.remove(\"None\")\n",
    "        except:\n",
    "            break\n",
    "    \n",
    "    test2 = []\n",
    "    for i in adjust2:\n",
    "        test2.append(int(i))\n",
    "        \n",
    "    try:\n",
    "        test2[-1] = test2[-1] * 3\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        return sum(test2)/len(test2)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928622e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63e045a6",
   "metadata": {},
   "source": [
    "# 코드 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ad4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\", index_col = 0)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50d3446",
   "metadata": {},
   "source": [
    "- 각 클러스터별로 모으기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1191a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#클러스터끼리 모으기\n",
    "clu0 = data[data['cluster'] == 0].reset_index(drop = True)\n",
    "clu1 = data[data['cluster'] == 1].reset_index(drop = True)\n",
    "# clu2 = data[data['cluster'] == 2].reset_index(drop = True)\n",
    "clu3 = data[data['cluster'] == 3].reset_index(drop = True)\n",
    "# clu4 = data[data['cluster'] == 4].reset_index(drop = True)\n",
    "clu5 = data[data['cluster'] == 5].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df711aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf 단어 중에서 키워드 5개 선정\n",
    "word_list0 = ['물레길', '자라섬', '숙정문', '비진도', '백악산']\n",
    "word_list1 = ['펩타이드', '여에스더', '락토바실러스' ,'콜라겐', '콜레올로']\n",
    "# word_list2 = ['기념일', '카네이션', '결혼기념일', '생신', '스승의날']\n",
    "word_list3 = ['이퀼리브리엄', '마르티니크', '라치몬트', '메인스트리트' ,'스쿱쿠키']\n",
    "# word_list4 = ['월세', '대출', '고시텔', '보증금', '전세']\n",
    "word_list5 = ['참다랑어', '곰치', '비빔국수', '순두부찌개', '곱창전골']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599cb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아자아자 화이팅!!\n",
    "def lets_go(cluster, word_list):\n",
    "    \n",
    "    target = []\n",
    "    target_num = []\n",
    "    index = []\n",
    "    for i, text in enumerate(cluster['review']) : #키워드 중 하나라도 포함되어 있는 게시글 수집\n",
    "        for word in word_list :\n",
    "            if word in ast.literal_eval(text):\n",
    "                \n",
    "                target_num.append(ast.literal_eval(text).index(word))\n",
    "                target.append(text)\n",
    "                index.append(i)\n",
    "                break\n",
    "    \n",
    "    importance = len(target)\n",
    "    print(\"키워드를 포함하는 게시물 수: \", len(target))\n",
    "    target = list(target)\n",
    "    \n",
    "    sentiment = []\n",
    "    for i, text in tqdm(enumerate(target)): #포함된 게시물에 한해서만 감성분석 실시\n",
    "        tokens = ast.literal_eval(text) #review i번째 토큰화\n",
    "        \n",
    "        num = 0\n",
    "        \n",
    "        try:\n",
    "            for token in tokens[target_num[i]-5:target_num[i]+5]:\n",
    "                if score_word(token) == 'None':\n",
    "                    pass\n",
    "                else:\n",
    "                    num += float(score_word(token))\n",
    "                    \n",
    "            sentiment.append(num)\n",
    "                    \n",
    "        except :\n",
    "            sentiment.append(0)\n",
    "                             \n",
    "        \n",
    "                             \n",
    "    cluster['sentiment'] = 0\n",
    "    \n",
    "    k = 0\n",
    "    for dex in index :\n",
    "\n",
    "        cluster['sentiment'][dex] = sentiment[k]\n",
    "        k += 1\n",
    "        \n",
    "    return cluster, importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db489e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clu0, clu0_importance = lets_go(clu0, word_list0)\n",
    "clu0.to_csv('sentiment0.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "clu1, clu1_importance = lets_go(clu1, word_list1)\n",
    "clu1.to_csv('sentiment1.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "# clu2, clu2_importance = lets_go(clu2, word_list2)\n",
    "# clu2.to_csv('sentiment2.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "clu3, clu3_importance = lets_go(clu3, word_list3)\n",
    "clu3.to_csv('sentiment3.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "# clu4, clu4_importance = lets_go(clu4, word_list4)\n",
    "# clu4.to_csv('sentiment4.csv', encoding = 'utf-8-sig')\n",
    "\n",
    "clu5, clu5_importance = lets_go(clu5, word_list5)\n",
    "clu5.to_csv('sentiment5.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b3039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfaction0 = clu0.sentiment.sum() / clu0_importance\n",
    "satisfaction1 = clu1.sentiment.sum() / clu1_importance\n",
    "# satisfaction2 = clu2.sentiment.sum() / clu2_importance\n",
    "satisfaction3 = clu3.sentiment.sum() / clu3_importance\n",
    "# satisfaction4 = clu4.sentiment.sum() / clu4_importance\n",
    "satisfaction5 = clu5.sentiment.sum() / clu5_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b6193",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = [satisfaction0, satisfaction1, satisfaction3, satisfaction5] #클러스터 갯수에 맞춰서 수정\n",
    "\n",
    "#  만족도 점수를 도출\n",
    "satisfaction = []\n",
    "for i in sentiment:\n",
    "    stm = 10 * ((i - min(sentiment)) / (max(sentiment) - min(sentiment)))\n",
    "    satisfaction.append(stm)\n",
    "satisfaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21700a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = [clu0_importance, clu1_importance,clu3_importance, clu5_importance]\n",
    "\n",
    "importance = []\n",
    "for i in size:\n",
    "    sz = 10 * ((i - min(size)) / (max(size) - min(size)))\n",
    "    importance.append(sz)\n",
    "importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c9eca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62bd4289",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9ae16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling(series):\n",
    "    minn = np.min(series)\n",
    "    maxx = np.max(series)\n",
    "    return [(i-minn)/(maxx-minn) for i in series]\n",
    "\n",
    "def visualize(importance, satisfaction):\n",
    "    jwapyo = []\n",
    "    ddex = []\n",
    "    if len(importance) != len(satisfaction):\n",
    "        raise Exception(\"Importance와 Satisfaction의 길이가 다릅니다.\")\n",
    "\n",
    "    for i in range(len(importance)):\n",
    "        jwapyo.append([importance[i], satisfaction[i]])\n",
    "    \n",
    "    x, y = zip(*jwapyo)\n",
    "    colors = [\"purple\", \"r\", \"b\", \"darkblue\", \"navy\", 'gold', 'goldenrod', 'darkgoldenrod', 'khaki', 'g', \"lime\", \"forestgreen\"]\n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i], y[i], label = labels[i], color = colors[i])\n",
    "\n",
    "    plt.legend(loc = \"upper right\", bbox_to_anchor=(1.3, 1))\n",
    "\n",
    "    plt.xlabel(\"Scale\", fontsize = 12)\n",
    "    plt.ylabel(\"Sentiment\", fontsize = 12)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b1167",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.DataFrame({'Importance': importance, \n",
    "                   'Satisfaction': satisfaction})\n",
    "dfs = dfs.fillna(0)\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca839c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('fixed_sentiment.txt','wb') as f:\n",
    "    pickle.dump(dfs, f) #쓰기모드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402566ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('fixed_sentiment.txt','rb') as f:\n",
    "    dfs = pickle.load(f) #불러오기, 읽기모드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac940b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
